{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sized-kitchen",
   "metadata": {},
   "source": [
    "# Challenges week 6\n",
    "\n",
    "Now that you have some experience with working with APIs and playing around with this data, it's time for you to combine and apply your knowledge. You will start working on these challenges in the tutorial and will be asked to complete them by the end of the week. \n",
    "\n",
    "In each challenge, you are asked to provide the programing solution to it as well as a technical interpretation explaining the steps taken and the result.\n",
    "\n",
    "Some important notes for the challenges:\n",
    "\n",
    "* If you get an error message, try to troubleshoot it (using Google often helps). If all else fails, go to the next excercise (but make sure to hand it in).\n",
    "* We will make sure to provide feedback and improvement suggestions in the rubric. Make sure to read them; they will help you improve next week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-endorsement",
   "metadata": {},
   "source": [
    "# Challange 1 \n",
    "\n",
    "Here is a list of easy to use APIs related to enterntainment https://github.com/public-apis/public-apis#entertainment with little or no authentication. We will now use the RandomUselessFacts API, for which the documentation is very simple and can be found here https://uselessfacts.jsph.pl/. \n",
    "1. Interact with the API to get access to a random fact or the fact of the day. \n",
    "2. Write a function that builds upon your initial script and allows for increased functionality/interaction with the API. The most obvious option here is to write a function that allows you to collect many facts in a neat fashion using the /random endpoint. For the function, provide the necessary code and a short explanation of the working of the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "a_fact = requests.get('https://uselessfacts.jsph.pl/today.json')\n",
    "a_fact\n",
    "#I get the appropriate response code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e1eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's the content\n",
    "a_fact.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that retrieves thrity random facts\n",
    "fact_list = []\n",
    "def get_a_fact():\n",
    "    for i in range(1,30):\n",
    "        a_fact =requests.get('https://uselessfacts.jsph.pl/random.json')\n",
    "        fact_list.append(a_fact.content)\n",
    "        return(fact_list)\n",
    "my_facts = get_a_fact()\n",
    "my_facts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-upper",
   "metadata": {},
   "source": [
    "# Challenge 2\n",
    "\n",
    "1. Look through the list of APIs above and write a script to interact with an API of your choosing. Write a script to interact with this API using the requests library and the GET method (make sure to consult the API documentation to make the code work) to retrieve at least 20 observations/rows into a dataframe from the json file response provided by the API. Provide the necessary code and a short explanation of the working of it (what happens at different steps).\n",
    "\n",
    "2.  Explore the dataset using the skills learned in previous weeks including essential steps such as checking column names or dict keys, data types, missing values and looking at relevant descriptive statistics. Based on it write a short summary about the dataset. <br>*Tip: not all steps such as merging or selecting relevant columns are necessary, but make sure to explore how dataset looks like, its columns and data types, missing data, and descriptive statistics).*\n",
    "\n",
    "3. Make sure that the API chosen allows for data that can generate one simply visualisation based on one or two variables (e.g. a bar chart, line plot, scatterplot). Generate this visualisation. Justify your choice for the visualisation type. <br> *Tip: when choosing a visualisation, think about measurement level of your variables.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No custom solution can be provided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322f7e0",
   "metadata": {},
   "source": [
    "# Challenge 3 \n",
    "\n",
    "The dataset `example_tweets.json` is the json  response returned from the Twitter API. This is a data collected using the keyword search surveillance - tweets that include this keyword are included in the dataset. On [this website](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet) you can find the documentation of the API and the columns it returns. In this challenge, you will explore this data and identify possible privacy and ethical issues with it.\n",
    "\n",
    "\n",
    "1. Use pandas to load this data into a dataframe. \n",
    "\n",
    "2. Explore this dataset and variables using the skills you have learned in the class. Make sure to check how the dataset looks like, what columns it has, what data type these columns have and if there are any missing values. Write a short descritpion of the dataset and answer the following questions:\n",
    "* How many languages are the tweets in?\n",
    "* How many retweets did the tweets recieve on average?\n",
    "* Is the retweets number higher or lower for tweets that contain sensitive links vs. the one's with non-sensitive and no links? *Tip: check in the documentation what missing values in column `possibly_sensitive` mean and consider what you need to do with them.*\n",
    "\n",
    "3. Imagine that you want to research if there is a relation between the topics in the text of the tweets about surveillance and number of retweets the tweets recieve. You want to include number of followers of the author of each tweet as a control variable. Hence, you need the columns with information on the text of the tweet (`text`), its number of retweets (`retweet_count`) and the number of followers of the author (included in `user`). \n",
    "* Minimize the dataset accordingly. Explain your minimization steps.\n",
    "* What other steps would you need to take to make sure that the data follows privacy protection principles discussed in the lecture? Give concrete examples based on the information available in your minimized dataset. *Tip: consider what identifiable and identified information the text and user columns contain.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac683f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
